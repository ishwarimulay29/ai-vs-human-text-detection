# AI-Generated vs Human-Written Essay Detection ğŸ¤–ğŸ“

A Natural Language Processing (NLP) project focused on distinguishing AI-generated essays from human-written text using classical machine learning, deep learning, and transformer-based models.

---

## ğŸ§  Project Overview

With the rapid adoption of large language models, AI-generated text increasingly resembles human writing, making reliable detection a challenging task. This project addresses the problem of automatically identifying whether an essay is written by a human or generated by AI.

The task is framed as a **binary classification problem**:
- **0** â†’ Human-written  
- **1** â†’ AI-generated  

The project follows a progressive modeling approach, starting from a strong classical baseline and extending to deep learning and transformer-based architectures.

---

## ğŸ”¬ Dataset

- ~500,000 essays consisting of both human-written and AI-generated text  
- Each sample contains:
  - Raw essay text
  - Binary label  
- Data split into training, development, and test sets  
- Class imbalance handled using **weighted precision, recall, and F1-score**

---

## ğŸ§¹ Preprocessing & Feature Engineering

Key preprocessing and feature engineering steps include:
- Text length and sentence-level statistics  
- Lexical diversity (Type-Token Ratio)  
- Readability metrics (Flesch Reading Ease, Automated Readability Index)  
- Stop-word and punctuation ratios  
- TF-IDF vectorization for classical models  

These features capture stylistic and structural differences between human and AI-generated text.

---

## ğŸ› ï¸ Models Used

### ğŸ§ª Strong Baseline
- **Linear SVM with TF-IDF features**
- Serves as a high-performing classical NLP baseline

### ğŸ§  Extension 1: Bi-directional LSTM
- Sequence-based neural model trained on raw text
- Captures long-range dependencies and contextual patterns
- Implemented as an extension over the strong baseline

### ğŸ¤– Extension 2: Fine-Tuned BERT
- Transformer-based classifier using **bert-base-uncased**
- Fine-tuned end-to-end for AI vs human text detection
- Captures subtle linguistic and contextual cues beyond surface features

---

## ğŸ“Š Results

| Model | Accuracy | F1 Score |
|------|----------|----------|
| Majority Baseline | ~62% | ~48% |
| SVM + TF-IDF | ~90% | ~89% |
| Bi-LSTM | ~98% | ~97% |
| BERT ğŸ”¥ | ~99.9% | ~99.8% |

âœ… Context-aware deep learning models significantly outperform classical approaches, with BERT achieving near-perfect performance on this dataset.

---

## ğŸ“Œ Key Features

- End-to-end NLP pipeline for AI-generated text detection  
- Clear progression from classical ML to deep learning and transformers  
- Robust handling of class imbalance  
- Emphasis on contextual and sequence-aware modeling  
- Reproducible and modular notebook-based workflow  

---

## ğŸ“š Files in this Repository

| File | Description |
|------|------------|
| `strong_baseline.ipynb` | Linear SVM + TF-IDF strong baseline implementation |
| `extension1.ipynb` | Bi-directional LSTM model for sequential text modeling |
| `extension1.md` | Architecture details and analysis for Bi-LSTM extension |
| `extension2.ipynb` | Fine-tuned BERT (bert-base-uncased) classifier |
| `presentation_slides.pdf` | Final project presentation slides |
| `README.md` | Project overview and documentation |
| `LICENSE` | MIT License |

---

## ğŸš€ How to Use

```bash
# Clone the repository
git clone https://github.com/ishwarimulay29/ai-vs-human-text-detection
cd ai-vs-human-text-detection

# Install dependencies
pip install -r requirements.txt

# Launch notebooks
jupyter notebook
